{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\expect}{\\mathrm{E}}\n",
    "\\newcommand{\\prob}{\\mathrm{P}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability, Conditionality and Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "A probabilistic model is a mathematical description of an uncertain situation. Probabilistic modeling can usually be broken down into three basic steps:  \n",
    "\n",
    "1. The description of the sample space, that is, the set of possible outcomes of a given experiment. The sample space elements should be mutually exclusive and collectively exhaustive.\n",
    "2. The (possibly indirect) specification of the probability law (the probability of each event).  The law might be based on frequency of occurrence or subjective belief.\n",
    "3. The calculation of probabilities and conditional probabilities of various events of interest. \n",
    "\n",
    "The probability law must follow the probability axioms of non-negativity, normalization (probability of sample space is 1), and additivity. \n",
    "\n",
    "Based on this the probability of an event \n",
    "$$ \\prob(\\{s_1, s_2, s_3, \\dots, s_n\\}) = \\prob(\\{s_1\\}) + \\prob(\\{s_2\\}) + \\prob(\\{s_3\\}) + \\dots + \\prob(\\{s_n\\}) $$\n",
    "\n",
    "If the probability of all outcomes is the same then \n",
    "$$\\prob(A)= \\frac{(\\textrm{no. of elements in }A)}{n} $$ \n",
    "Here $A$ is a subset of the sample space and $n$ is the total number of elements in the sample space.\n",
    "\n",
    "Similar rules apply for continuous models, where instead of talking in terms of particular outcomes, we talk in terms of intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probability\n",
    "\n",
    "$\\prob(A \\mid B)$ : Out of the total probability assigned to event $B$, what fraction also gives rise to event $A$. (Out of the total probability assigned to outcomes that give rise to event $B$, what fraction of probability is assigned to outcomes that also give rise to event $A$.) Considering event $B$ as the Universal Set, what is the probability of event $A$ occuring.  \n",
    "\n",
    "From the definition, the equation for conditional probability is very intuitive. It is \n",
    "$$ \\prob(A \\mid B) = \\frac{\\prob(A \\cap B)}{\\prob(B)} $$\n",
    "\n",
    "Conditional probabilities can also be viewed as a probability law on a new universe $B$, because all of the conditional probability is concentrated on $B$. $\\prob(A \\mid B)$ is directly proportionate to the outcomes that cause both $A$ and $B$ events. $\\prob(B)$ is the normalizing factor.  \n",
    "\n",
    "$$\\prob(A \\cap B) = \\prob(B) \\times \\prob(A \\mid B)$$\n",
    "This is called the **Product Rule** in Probability Theory. How many times $A$ and $B$ occur together? How many times  does $B$ occur? Out of the times $B$ occurs, how many times does $A$ occur?  \n",
    "\n",
    "<img src=\"images/cond_venn.jpg\">\n",
    "\n",
    "Venn diagrams aren’t always the best way of visualizing conditional probability. A better tool is - a probability tree. Probability trees don’t just help you visualize probabilities; they can help you to calculate them, too. Each branch of the probability tree shows the probability of outcomes given the outcome of the branch it is linked to. You can find probabilities involving intersections by multiplying the probabilities of linked branches together. As an example, suppose you want to find $\\prob(A \\cap B)$. You can find this by multiplying $\\prob(B)$ and $\\prob(A \\mid B)$ together. \n",
    "\n",
    "<img src=\"images/ptree.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods of Calculating Probabilities\n",
    "\n",
    "1. Counting method, in case of finite outcomes, where each outcome has equal probability.  \n",
    "<img src=\"images/counting.jpg\"><br>\n",
    "\n",
    "2. Sequential method, where we model the problem as a tree. The probability of various events are obtained by multiplying conditional probabilities along the corresponding paths of the tree.  \n",
    "<br>\n",
    "\n",
    "3. Divide and Conquer method, where we first calculate $\\prob(B \\mid A_i)$ i.e. the probability of $B$ happening in different partitions of the sample space, and then combine these probabilities to get the total probability of $B$ happening in the entire sample space. $$ \\prob(B) = \\sum_i \\prob(A_i) \\prob(B \\mid A_i) $$ This is called the **Sum Rule** in Probability Theory.  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Theorem of Inference\n",
    "\n",
    "Bayes’ Theorem is derived directly from the definition of Conditional Probability. To get a background on Bayesian Inference go through Lec 2.5. Basically we have an event $B$ (which can be recorded/measured, like generation of alarm by a radar). Based on that, we try to infer which condition was true when $B$ happened, $A_1$ (aircraft was present), $A_2$ (goose was present), $A_3$ (the sky was clear) and so on.  Therefore we try to calculate $\\prob(A_1|B)$, $\\prob(A_2|B)$, etc.\n",
    "\n",
    "Bayes’ Theorem says that:\n",
    "\\begin{align}\n",
    "\\prob(A_i \\mid B) &= \\frac{\\prob(A_i) \\prob(B \\mid A_i)}{\\prob(B)}\\\\\\\\\n",
    "&= \\frac{\\prob(A_i) \\prob(B \\mid A_i)}{\\sum_j{\\prob(A_j)\\prob(B \\mid A_j)}}\\\\\n",
    "\\end{align}\n",
    "Here,  \n",
    "* $\\prob(A_i)$, is known as the **prior**. It is the probability of occurrence of $A_i$, prior to the information that the event $B$ has occurred.  \n",
    "<br>\n",
    "\n",
    "* $\\prob(B \\mid A_i)$ is the **likelihood**.  It is the likelihood of **data** (observable/recordable event) happening when $A_i$ event has occurred.  \n",
    "<br>\n",
    "\n",
    "* $\\prob(A_i \\mid B)$ is called the **posterior**, because by this time we have already observed the event and have come to know that the *data* event has already occurred. We are trying to find the probability of a thing having happened back in time, posterior probability.  \n",
    "<br>\n",
    "\n",
    "*  $\\prob(B)$ or $\\prob(\\mathrm{data})$ doesn’t have a name in general. It is the probability that data event has taken place. Generally, data event has some observable/measurable characteristics that helps us calculate its probability of occurrence.  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence\n",
    "\n",
    "It intuitively means that event $A$ taking (or not taking) place doesn’t give us any information about whether another event $B$ will take place (or not). Mathematically it is written as $\\prob(A \\cap B) = \\prob(A) \\times \\prob(B)$. Also written as $\\prob(A|B) = \\prob(A)$ using conditional probabilities. Remember that if two events are independent, they aren’t necessarily conditionally independent and vice-versa.\n",
    "\n",
    "Also, if events $A$, $B$ and $C$ are pairwise independent, it doesn’t mean that they are actually independent i.e. $\\prob(A \\cap B \\cap C)$ is not necessarily equal to $\\prob(A) \\times \\prob(B) \\times \\prob(C)$, if $A$, $B$ and $C$ are pairwise independent.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
