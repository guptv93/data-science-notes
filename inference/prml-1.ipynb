{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRML L-1 \n",
    "# Introduction\n",
    "*Summary by Vaibhav Gupta (vvg239@nyu.edu)*\n",
    "\n",
    "The chapter starts by discussing how to find the best fit polynomial curve for given data points (observations) by adjusting the coefficients (weights) of the polynomial terms. Functions, such as the polynomial, which are linear in the unknown parameters have important properties and are called linear models (the linearity is not with respect to observations).  \n",
    "\n",
    "The first error function considered here is the sum of squared errors between the predictions and target values. We see that when we take higher order polynomials, the error function decreases. As we keep going higher, we obtain an excellent fit to the training data. In fact, if polynomial is sufficiently high, it passes exactly through each data point and E(w) = 0. However, the fitted curve oscillates wildly and gives a very poor representation of the target function. This latter behaviour is known as **over-fitting**.  \n",
    "\n",
    "This feels paradoxical because lower order polynomials are special cases of higher order polynomials. But the reason for over-fitting is that when we increase the order of polynomial, the model has higher degrees of freedom and the weights get very finely tuned to the data by developing large positive and negative values so that the corresponding polynomial function matches each of the data points exactly, but between data points the function exhibits the large oscillations. What has happened is that the polynomial has fit the bias noise and actual stochastic noise with its huge degrees of freedom, instead of fitting the target function! The section also introduces the technique of weight decay for preventing the weights from assuming very large +ve/-ve values.\n",
    "\n",
    "\n",
    "## Probability Theory  \n",
    "\n",
    "Here we are first introduced to two very basic rules of probability : \n",
    "1. **Sum Rule** : The marginal probability $P(x)$ is the sum of all joints probabilities $P(x,y), \\forall y, X =x$  \n",
    "2. **Product Rule** : The join probability of $X$ and $Y$ is equal to conditional probability of $X$ w.r.t $Y$ multiplied by probability of $Y$.  \n",
    "\\begin{align}\n",
    "& P(X=x_i) = \\sum_{j=1}^{L}P(X=x_i,Y=y_j)\\\\\n",
    "& P(X,Y) = P(X | Y) P(Y)\\\\\n",
    "\\end{align}\n",
    "\n",
    "It also goes over other basics like definition of Exceptation and Covariance. Then it goes over the Bayes rule which states that the posterior distribution is directly proportionate to prior into likelihood.  \n",
    "\n",
    "Gaussian Probability Distribution : \n",
    "$$ P(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} $$\n",
    "where $\\mu$ is the mean of the distribution and $\\sigma^2$ is the variance. Then we study how to find the mean and variance of a normal distribution given noisy observations from a Gaussian distribution.  \n",
    "\n",
    "\n",
    "## Decision Theory  \n",
    "\n",
    "Probability Theory tells us how to calculate the posterior distribution of a given input $x$ belonging to a particular class $C_k$ i.e. $P(C_k|x)$. Now how do we decide which class to categorize $x$ in given this posterior distribution? Decision Theory to the rescue.  \n",
    "\n",
    "If we want to minimize the misclassification rate, then we just assign $x$ to the class $C_k$ for which $P(C_k | x)$ is the maximum. But we don't always just want to minimize the misclassification rate. Sometimes, it is clearly better to make fewer mistakes of the second kind, even if this is at the expense of making more mistakes of the first kind. We can formalize such issues through the introduction of a loss function, also called a cost function, which is a single, overall measure of loss incurred in taking any of the available decisions or actions. Our goal is then to minimize the total loss incurred.\n",
    "\n",
    "In fact, we can identify three distinct approaches to solving decision problems, all of which have been used in practical applications.\n",
    "1. In the first approach we find the joint distribution of $x$ and $C_k$ i.e. $P(C_k|x)$. We then normalize to find the posterior distribution and base our classification decision on this posterior probability. Approaches that explicitly or implicitly model the distribution of inputs as well as outputs are known as generative models, because by sampling from them it is possible to generate synthetic data points in the input space.\n",
    "2. Here we find the posterior class probabilities and then use decision theory to find the class of $x$. Approaches that model the posterior probabilities directly are called discriminative models.\n",
    "3. Don't even deduce the posterior probability. Just find a function which classifies the observations into different classes. Like a perceptron. In this case, we won't know how confident we are of a classification. We will just know the final output.  \n",
    "\n",
    "Approach 1 is the most demanding as $X$ has a very high dimensionality and finding its joint distribution is very difficult. But if we have a generative model (Approach 1) we can generate data points (Duh!) and that is a big deal.  \n",
    "With approach 3 we directly get the needed class but we dont get a posterior distribution. Thus we miss out on many advantages including minimizing risk, reject option etc.  \n",
    "\n",
    "\n",
    "## Information Theory  \n",
    "\n",
    "Information Theory delves into how much information the value of random variable may provide to us. $h(x)$ is a function of the random variable $X$ and tells us how much information the variable is carrying. If the variable assumes a very non-probable value, we get much more information as compared to $X$ assuming a regular value that it always assumes.\n",
    "$$h(x) = -log_2p(x)$$\n",
    "\n",
    "$H$ is the entropy function and assigns higher value to a variable that is more random than another variable which assumes a particular value with very high probability.\n",
    "$$H[x] = - \\sum_x{p(x)log_2p(x)}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
